{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4edba9-ee53-4c6a-9688-ef44161103a5",
   "metadata": {},
   "source": [
    "This scripts expects the following folder organization:\n",
    "- home_folder\n",
    "    - input1_folder: contains: image files; PVN rois files. Image files are tiff files with dimensions ch, x, y. Ch ('channel') has Nuclei (DAPI) at 4th position. PVN rois files are .zip or .roi Java-based roi files (drawn in ImageJ); their names match the corresponding Image file (but for the extension).\n",
    "    - input2_folder: contains Cells roi files. Cells rois are .zip Java-based roi files (drawn in ImageJ). Their names match the corresponding Image files, but for the extension. Per each cell there is a 'Nucleus' and a 'Cell' roi, which is the expanded nucleus from pipeline step-3.\n",
    "\n",
    "Outputs are saved in an output_folder inside home_folder\n",
    "\n",
    "NOTES: 1) by default the scripts expects to find the following information in the file directory: experiment name; mouse name; sex; slice position. 2) This scripts works on the pipeline step-3 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84713dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage import exposure\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.util import img_as_int, img_as_uint, img_as_float, img_as_float32, img_as_ubyte\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "\n",
    "from findmaxima2d import find_maxima, find_local_maxima #Version that has been installed into python site-packages.\n",
    "import czifile\n",
    "from read_roi import read_roi_zip\n",
    "import roifile\n",
    "from roifile import ImagejRoi\n",
    "from skimage.draw import polygon\n",
    "\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec255f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicate the directory of the home_folder\n",
    "home_directory = r\"/Users/alessandro_ulivi/ownCloud - alessandro.ulivi@lin-magdeburg.de@owncloud.gwdg.de/RNAscope/Analysis/Analysis_directory/Experiment2\"\n",
    "\n",
    "#Join home_directory with input1_folder (Step_1_output), input2_folder (Step_3_output) and output_folder (Step_4_output)\n",
    "step1_path_output = os.path.join(home_directory, \"Step_1_output\")\n",
    "#step2_path_output = os.path.join(home_directory, \"Step_2_output\")\n",
    "step3_path_output = os.path.join(home_directory, \"Step_3_output\")\n",
    "step4_path_output = os.path.join(home_directory, \"Step_4_output\")\n",
    "\n",
    "#Create output_folder, if it doesn't exist\n",
    "if not os.path.exists(step4_path_output):\n",
    "    os.makedirs(step4_path_output)\n",
    "\n",
    "\n",
    "#Generates a list of the files in a given directory avoiding hidden files\n",
    "def listdirNHF(path100):\n",
    "    \"\"\"\n",
    "    forms a list of files in an directory, avoiding hidden files. Hidden files are identified by their names starting with a '.'\n",
    "    inputs: folder directory\n",
    "    outputs: list of all non-hidden files in the input directory\n",
    "    \"\"\"\n",
    "    #Initialize output list\n",
    "    the_F_list = []\n",
    "    \n",
    "    #Collect input folder elements in a list\n",
    "    start_list = os.listdir(path100)\n",
    "    \n",
    "    #Iterate through the elements of the list\n",
    "    for item in start_list:\n",
    "        \n",
    "        #If the name of the element doesn't start with a '.', append it to the output list\n",
    "        if not item.startswith('.'):\n",
    "            the_F_list.append(item)\n",
    "    \n",
    "    #Return the output list\n",
    "    return the_F_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4d3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters for the analysis\n",
    "\n",
    "#histogram rescaling - set bottom and top percentils of signal intensity, to use when defining the rescaling range\n",
    "min_percentil = 0.1 #NOTE: this is irrelevant for the processing\n",
    "max_percentil = 99.995 #Parameter used in the analysis is 99.995\n",
    "\n",
    "\n",
    "#blob detection\n",
    "min_sigma_Ch1=1 #lower sigma min means detecting smaller blobs; ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "max_sigma_Ch1=8 #higher sigma max means detecting bigger blobs; ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "num_sigma_Ch1=4 #ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "threshold_Ch1=0.03 #Intensity threshold to detect blobs; used in the \"threshold\" parameter of the blob_log function\n",
    "overlap_Ch1=0.9 #when two blobs' areas overlap more than the specified threshold, the smallest is removed\n",
    "\n",
    "min_sigma_Ch2=1 #lower sigma min means detecting smaller blobs; ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "max_sigma_Ch2=8 #higher sigma max means detecting bigger blobs; ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "num_sigma_Ch2=4 #ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "threshold_Ch2=0.02 #Intensity threshold to detect blobs; used in the \"threshold\" parameter of the blob_log function\n",
    "overlap_Ch2=0.9 #when two blobs' areas overlap more than the specified threshold, the smallest is removed\n",
    "\n",
    "min_sigma_Ch3=1 #lower sigma min means detecting smaller blobs; ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "max_sigma_Ch3=8 #higher sigma max means detecting bigger blobs; ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "num_sigma_Ch3=4 #ref to https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log\n",
    "threshold_Ch3=0.03 #Intensity threshold to detect blobs; used in the \"threshold\" parameter of the blob_log function\n",
    "overlap_Ch3=0.9 #when two blobs' areas overlap more than the specified threshold, the smallest is removed\n",
    "\n",
    "\n",
    "#find maxima\n",
    "maxima_threshold_Ch1 = 15\n",
    "maxima_threshold_Ch2 = 12\n",
    "maxima_threshold_Ch3 = 15\n",
    "\n",
    "#Names\n",
    "experiment_position = home_directory[-1:] #Specify how to extract the experiment information. If there is no experiment information, indicate any string\n",
    "sex_position = [None,1] #Specify how to extract the sex information. In this case, the list indicates the start and end of Image_name slicing (None is used to start from the beginning of Image_name). If there is no sex information, indicate any string.\n",
    "mouse_position = [2,4] #Specify how to extract the mouse information. In this case, the list indicates the start and end of Image_name slicing. If there is no mouse information, indicate any string\n",
    "slice_position = [7,11] #Specify how to extract the slice_position information. In this case, the list indicates the start and end of Image_name slicing. If there is no sex information, indicate any string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cdc3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize files in a dictionary: each \"Image file name\" (string without extension) is linked to a dictionary_2.\n",
    "#Dictionary_2 links: 1) 'original_name' to \"Image file name\"+.tif extension;  2) 'rois_pvn' to \"Image file name\"+.zip or .roi extension; 3) 'cell_rois' to \"Image file name\"+\"_expanded\"+.zip extension \n",
    "\n",
    "organized_dictionary = {}\n",
    "for f in listdirNHF(os.path.join(home_directory, step1_path_output)):\n",
    "    filename = str(f)[:-4]\n",
    "    if f[-4:]==\".tif\":\n",
    "        organized_dictionary[filename]={}\n",
    "        organized_dictionary[filename]['original_image']= str(f)\n",
    "        pvn_rois_name = filename + \".zip\"\n",
    "        if os.path.exists(os.path.join(os.path.join(home_directory, step1_path_output),pvn_rois_name)):\n",
    "            organized_dictionary[filename]['rois_pvn'] = pvn_rois_name\n",
    "        else:\n",
    "            pvn_rois_name2 = filename + \".roi\"\n",
    "            organized_dictionary[filename]['rois_pvn'] = pvn_rois_name2\n",
    "        cell_rois_name = filename+\"_expanded.zip\"\n",
    "        organized_dictionary[filename]['cell_rois'] = cell_rois_name\n",
    "\n",
    "# print(organized_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a35055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#functions for processing\n",
    "\n",
    "def form_polygon(original_picture, my_roi_coordinates):\n",
    "    \"\"\"\n",
    "    inputs: rois coordinates (list of tuples, each tuple is: col, row) and 2D image\n",
    "    oputputs: mask (image with same shape as input, but with 1 in the rois pixels, 0 otherwise), list of row coordinates, list of col coordinates\n",
    "    \"\"\"\n",
    "    list_x_col = []\n",
    "    list_y_row = []\n",
    "    for c in my_roi_coordinates:\n",
    "        list_x_col.append(c[0]-1)\n",
    "        list_y_row.append(c[1]-1)\n",
    "    \n",
    "    arr_x_col = np.asarray(list_x_col)\n",
    "    arr_y_row = np.asarray(list_y_row)\n",
    "    \n",
    "    img = np.zeros((original_picture.shape[0], original_picture.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    rr, cc = polygon(arr_y_row, arr_x_col)\n",
    "    img[rr, cc] = 1\n",
    "    \n",
    "    return img, rr, cc\n",
    "\n",
    "\n",
    "def get_my_mode_value(arr_2D):\n",
    "    \"\"\"\n",
    "    given a 2D numpy array, returns a single mode value into a list. The value is calculated as following: 1) Calculate a 40000-bins histogram distribution; 2) each bin count is defined as a \"spike\" if its delta change from previous and following bin counts are higher than, respectively: (mean of previous 3 delta changes + 15*(standard deviation of previous 3 delta changes)) and (mean of following 3 delta changes + 15*(standard deviation of following 3 delta changes))\n",
    "    3) the mode value is the bin which as the highest counts and is not a spike.\n",
    "    \"\"\"\n",
    "    hist, bin_edges = np.histogram(arr_2D, bins=np.linspace(0,65535,40000))\n",
    "    list_counts = list(hist.ravel())\n",
    "    \n",
    "    step_forw = 3\n",
    "    step_back = 3\n",
    "    std_numb = 15\n",
    "    \n",
    "    spikes = []\n",
    "    i=0\n",
    "    for q in range(len(list_counts)):\n",
    "        if i<step_forw:\n",
    "            following_deltas = [abs(j-list_counts[list_counts.index(j)+1]) for j in list_counts[i+1:i+step_forw]]\n",
    "            previous_deltas = [abs(j-list_counts[list_counts.index(j)-1]) for j in list_counts[1:i]]\n",
    "            total_deltas = following_deltas + previous_deltas\n",
    "        \n",
    "        elif i>(len(list_counts)-4):\n",
    "            following_deltas = [abs(j-list_counts[list_counts.index(j)+1]) for j in list_counts[i+1:-1]]\n",
    "            previous_deltas = [abs(j-list_counts[list_counts.index(j)-1]) for j in list_counts[i-step_back:i]]\n",
    "            total_deltas = following_deltas + previous_deltas\n",
    "        else:\n",
    "            following_deltas = [abs(j-list_counts[list_counts.index(j)+1]) for j in list_counts[i+1:i+step_forw]]\n",
    "            previous_deltas = [abs(j-list_counts[list_counts.index(j)-1]) for j in list_counts[i-step_back:i]]\n",
    "            total_deltas = following_deltas + previous_deltas\n",
    "        \n",
    "        mean_delta, std_delta = np.mean(total_deltas), np.std(total_deltas)\n",
    "        \n",
    "        if i==0:\n",
    "            follow_i = list_counts[i+1]\n",
    "            delta_follow = abs(list_counts[i]-follow_i)\n",
    "            if delta_follow>(mean_delta+15*std_delta):\n",
    "                spikes.append(list_counts[i])\n",
    "            \n",
    "        elif i==(len(list_counts)-1):\n",
    "            previous_i = list_counts[i-1]\n",
    "            delta_previous = abs(list_counts[i]-previous_i)\n",
    "            if delta_previous>(mean_delta+15*std_delta):\n",
    "                spikes.append(list_counts[i])\n",
    "            \n",
    "        else:\n",
    "            follow_i = list_counts[i+1]\n",
    "            previous_i = list_counts[i-1]\n",
    "            delta_follow = abs(list_counts[i]-follow_i)\n",
    "            delta_previous = abs(list_counts[i]-previous_i)\n",
    "            if ((delta_follow>(mean_delta+std_numb*std_delta)) and (delta_previous>(mean_delta+std_numb*std_delta))):\n",
    "                spikes.append(list_counts[i])\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "    sorted_list_counts = sorted(list_counts)\n",
    "    k = 1\n",
    "    mode_count = sorted_list_counts[-k]\n",
    "    while (mode_count in spikes):\n",
    "        mode_count = sorted_list_counts[-k]\n",
    "        k=k+1\n",
    "    \n",
    "    mode_idx_2Darr = np.argwhere(hist == mode_count)\n",
    "    mode_val_2Darr = bin_edges[mode_idx_2Darr].flatten().tolist()\n",
    "    if len(mode_val_2Darr)>1:\n",
    "        mode_val_2Darr = [np.mean(mode_val_2Darr)]\n",
    "    return mode_val_2Darr\n",
    "\n",
    "\n",
    "\n",
    "def my_intensity_rescaling(img2rescale, my_min_perc, my_max_perc):\n",
    "    \"\"\"\n",
    "    given a 2D numpy array, a min and a max percentil (integers or floats)\n",
    "    calculates the intensity values corresponding to the indicated min and max percentiles in the intensity histogram\n",
    "    calculates the mode value of the intensity histogram (using get_my_mode_value function)\n",
    "    rescales the intensity values of the 2D array withing a new range defined by the mode and max (derived from the percentiles) intensity values\n",
    "    returns the a new 2D array, identical to the input but with rescaled intensity values\n",
    "    \"\"\"\n",
    "    #find arrays modes\n",
    "    mode_val_I2R = get_my_mode_value(img2rescale)[0]\n",
    "\n",
    "    #find arrays percentiles\n",
    "    min_I2R, max_I2R = np.percentile(img2rescale, (my_min_perc, my_max_perc))\n",
    "\n",
    "    #equalize histograms\n",
    "    equalized_img_I2R = exposure.rescale_intensity(img2rescale, in_range=(mode_val_I2R, max_I2R))\n",
    "    \n",
    "    return equalized_img_I2R\n",
    "\n",
    "\n",
    "def my_find_maxima(file_to_analyze, my_ntol):\n",
    "    \"\"\"\n",
    "    input: 2D array (dtype int16, value range 0,255); threshold\n",
    "    output: coordinates of local intensity maxima (based on the python version of ImageJ \"Find Maxima\" https://github.com/dwaithe/MaximaFinder)\n",
    "    \"\"\"\n",
    "    local_max = find_local_maxima(file_to_analyze)\n",
    "    y, x, regs = find_maxima(file_to_analyze,local_max,my_ntol)\n",
    "    return y, x, regs\n",
    "\n",
    "\n",
    "\n",
    "def GetCiPVNwIntMaxBlobs(rescaled_Ch1_Ch2_Ch3, pvn__rois, rois_file, blobs_results, maxima_results, pvn_zip_files):\n",
    "    \"\"\"\n",
    "    GetCiPVNwIntMaxBlobs stays for \"Get Cells in the PVN with their Intensities, Maxima and Blobs\"\n",
    "    inputs: list of three 2D arrays to be analyzed\n",
    "            roifile of the pvn regions. Java-based roi file manually drawn on ImageJ\n",
    "            roifile of cells, nuclei and cytoplasms in the 2D arrays to analyze. One file is common to all three arrays. This is a Java-based roi file and is the result of pipeline step-3 (ImageJ expansion script). Cells names format is \"Cell #XXX\"; nuclei names format is \"Nucleus #XXX\"; cytoplasms names format is \"Cytoplasm #XXX\".\n",
    "            results of blobs detection from skimage.feature blob_log function in a list-like object. One result should be provided per each 2D array to analyze\n",
    "            results of maxima detection from my_find_maxima function in a list-like object. One result should be provided per each 2D array to analyze\n",
    "    outputs: Tuple of following measurments (output_position,output_measurement, output_format):\n",
    "    # 0 blobs_in_PVNcells_yx_rrcc_final_dict_Ch1; {\"c1\":[(y_rr,x_cc,radius),(y_rr,x_cc,radius)], \"c2\":[(y_rr,x_cc,radius), (y_rr,x_cc,radius)]}\n",
    "    # 1 blobs_in_PVNcells_yx_rrcc_final_dict_Ch2; {\"c1\":[(y_rr,x_cc,radius),(y_rr,x_cc,radius)], \"c2\":[(y_rr,x_cc,radius), (y_rr,x_cc,radius)]}\n",
    "    # 2 blobs_in_PVNcells_yx_rrcc_final_dict_Ch3; {\"c1\":[(y_rr,x_cc,radius),(y_rr,x_cc,radius)], \"c2\":[(y_rr,x_cc,radius), (y_rr,x_cc,radius)]}\n",
    "    # 3 blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch1; {\"c1\":(mean_radius,std_dev), \"c2\":(mean_radius,std_dev)}\n",
    "    # 4 blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch2; {\"c1\":(mean_radius,std_dev), \"c2\":(mean_radius,std_dev)}\n",
    "    # 5 blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch3; {\"c1\":(mean_radius,std_dev), \"c2\":(mean_radius,std_dev)}\n",
    "    # 6 maxima_in_PVNcells_yx_rrcc_final_dict_Ch1; {\"c1\":[(y_rr,x_cc),(y_rr,x_cc)], \"c2\":[(y_rr,x_cc), (y_rr,x_cc)]}\n",
    "    # 7 maxima_in_PVNcells_yx_rrcc_final_dict_Ch2; {\"c1\":[(y_rr,x_cc),(y_rr,x_cc)], \"c2\":[(y_rr,x_cc), (y_rr,x_cc)]}\n",
    "    # 8 maxima_in_PVNcells_yx_rrcc_final_dict_Ch3; {\"c1\":[(y_rr,x_cc),(y_rr,x_cc)], \"c2\":[(y_rr,x_cc), (y_rr,x_cc)]}\n",
    "    # 9 meanintensity_PVNcells_final_dict_Ch1; {\"c1\":[mean], \"c2\":[mean]}\n",
    "    # 10 meanintensity_PVNcells_final_dict_Ch2; {\"c1\":[mean], \"c2\":[mean]}\n",
    "    # 11 meanintensity_PVNcells_final_dict_Ch3; {\"c1\":[mean], \"c2\":[mean]}\n",
    "    # 12 area_PVNcells_yx_final_dict; {\"c1\":[area], \"c2\":[area]}\n",
    "    # 13 nuclei_centroids_yx_rrcc_dict; {\"c1\":(y_rr,x_cc), \"c2\":(y_rr,x_cc)}\n",
    "    # 14 area_nucleus_PVNcells_final_dict; {\"c1\":[area], \"c2\":[area]}\n",
    "    \"\"\"\n",
    "    #get PVN masks\n",
    "    if pvn_zip_files:\n",
    "        l_PVN_mask, l_PVN_rr, l_PVN_cc = form_polygon(rescaled_Ch1_Ch2_Ch3[0], pvn__rois[0].coordinates())\n",
    "        r_PVN_mask, r_PVN_rr, r_PVN_cc = form_polygon(rescaled_Ch1_Ch2_Ch3[0], pvn__rois[1].coordinates())\n",
    "    else:\n",
    "        l_PVN_mask, l_PVN_rr, l_PVN_cc = form_polygon(rescaled_Ch1_Ch2_Ch3[0], pvn__rois.coordinates())\n",
    "        r_PVN_mask, r_PVN_rr, r_PVN_cc = form_polygon(rescaled_Ch1_Ch2_Ch3[0], pvn__rois.coordinates())\n",
    "    \n",
    "    #test functining of PVN roi opening - uncomment the cells below and provide 2 axes to show the left and right pvn mask\n",
    "    # print(\"LEFT PVN\")\n",
    "    # ax2.imshow(l_PVN_mask)\n",
    "    # print(\"RIGHT PVN\")\n",
    "    # ax3.imshow(r_PVN_mask)\n",
    "    \n",
    "    #get blobs coordinates as tuples and collect them in a list - map blobs' coordinates to their radii\n",
    "    def get_blobs_coord_list_and_dict(detected_blobs):\n",
    "        \"\"\"\n",
    "        inputs: list of blobs coordinates and radii, as dectected from function skimage.feature.blob_log\n",
    "        outputs: 1) list of tuples, each tuple contains the y,x (row,column) position of each of the blob; 2) dictionary mapping each y,x coordinate of an individual blob, to its radius\n",
    "        \"\"\"\n",
    "        blobs_coordinates_list = []\n",
    "        blobs_coordinates_dict = {}\n",
    "        for b in detected_blobs:\n",
    "            tuple_rrcc_yx = (b[0],b[1])\n",
    "            blobs_coordinates_list.append(tuple_rrcc_yx)\n",
    "            if tuple_rrcc_yx not in blobs_coordinates_dict:\n",
    "                blobs_coordinates_dict[tuple_rrcc_yx] = b[2]\n",
    "            else:\n",
    "                print(\"somehow a blob was present multiple times\")\n",
    "        return blobs_coordinates_list, blobs_coordinates_dict\n",
    "    \n",
    "    blobs_coordinates_list_Ch1 , blobs_coordinates_dict_Ch1 = get_blobs_coord_list_and_dict(blobs_results[0])\n",
    "    blobs_coordinates_list_Ch2 , blobs_coordinates_dict_Ch2 = get_blobs_coord_list_and_dict(blobs_results[1])\n",
    "    blobs_coordinates_list_Ch3 , blobs_coordinates_dict_Ch3 = get_blobs_coord_list_and_dict(blobs_results[2])\n",
    "    \n",
    "    \n",
    "    #map cells roi names to their roi files; use nuclei' centroids to define rois' in PVN; backcalculate cells-in-PVN names from the nuclei-in-PVN names and save them (the cells-in-PVN names) in a list \n",
    "    cells_dict = {} #dictionary mapping each cell name to its roi file\n",
    "    names_of_cells_in_pvn = [] #list of the names of the cells which are in the PVN\n",
    "    nuclei_centroids_yx_rrcc_dict = {} #OUTPUT DICTIONARY mapping PVN-cell names to the coordinates (tuple: y,x or row,column) of their nuclei centroids\n",
    "    area_nucleus_PVNcells_final_dict = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list containing a single value: the area of their nuclei centroids\n",
    "    \n",
    "    for c in rois_file: #Iterate through cells' rois\n",
    "        #identify roi type based on its name (names are \"Cell #---\" or \"Nucleus #---\" or \"Cytoplasm #---\" where \"---\" is a 3 digit number)\n",
    "        c_name = list(c.name)\n",
    "        hashtag_position = c_name.index(\"#\")\n",
    "        if \"#\" not in c_name:\n",
    "            print(\"roi with no hashtag\")\n",
    "        type_of_roi = c.name[:hashtag_position-1]\n",
    "        \n",
    "        #if roi is a cell -> collect it in a dictionary mapping the cell name to the roi file\n",
    "        if type_of_roi==\"Cell\":\n",
    "            if c.name not in cells_dict:\n",
    "                cells_dict[c.name]=c\n",
    "            else:\n",
    "                print(\"this cell was already in the cell dictionary, is it present twice?\", c.name)\n",
    "        \n",
    "        \n",
    "        #if roi is a nucleus -> find the centroid; if the centroid is in the PVN -> backcalculate corresponding cell name and save it the \"names_of_cells_in_pvn\" list\n",
    "        elif type_of_roi==\"Nucleus\":\n",
    "            c_mask, c_rr, c_cc = form_polygon(rescaled_Ch1_Ch2_Ch3[0], c.coordinates()) #Gets cell mask\n",
    "            label_c_mask = label(c_mask) #transform cell mask in a label image\n",
    "            props_c = regionprops(label_c_mask) #measure properties of the label image\n",
    "            rr_y_centroid_c, cc_x_centroid_c = props_c[0]['centroid']  #Get centroid coordinates\n",
    "            area_nulceus = props_c[0]['area'] #Get cell area\n",
    "            value_l = l_PVN_mask[int(rr_y_centroid_c)-1, int(cc_x_centroid_c)-1] #Check if the centroid is in the left PVN\n",
    "            value_r = r_PVN_mask[int(rr_y_centroid_c)-1, int(cc_x_centroid_c)-1] #Check if the centroid is in the right PVN\n",
    "            if (value_l in [1,1.0]) or (value_r in [1,1.0]): #If nucleus centroid is in PVN\n",
    "                #test functining of PVN intersection - uncomment the cells below and provide an ax to plot the position of centroids in pvn\n",
    "                # circ = plt.Circle((int(cc_x_centroid_c)-1, int(rr_y_centroid_c)-1), 4, color='blue', linewidth=3, fill=False) #test functining of PVN intersection\n",
    "                # ax3.add_patch(circ) #test functining of PVN intersection\n",
    "                cell_roi_name = \"Cell \"+c.name[hashtag_position:] #Back-calculate cell's name\n",
    "                names_of_cells_in_pvn.append(cell_roi_name) #Collect cell name in 'names_of_cells_in_pvn' list\n",
    "                nuclei_centroids_yx_rrcc_dict[cell_roi_name]=(rr_y_centroid_c, cc_x_centroid_c) #Map cell name to centroid coordinates in 'nuclei_centroids_yx_rrcc_dict' dictionary\n",
    "                area_nucleus_PVNcells_final_dict[cell_roi_name]=[area_nulceus] #Map cell name to nucleus area in 'area_nucleus_PVNcells_final_dict' dictionary\n",
    "            #test functining of PVN intersection - uncomment the cells below and provide an ax to plot the position of centroids outside pvn\n",
    "            # else: #test functining of PVN intersection\n",
    "            #     circ = plt.Circle((int(cc_x_centroid_c)-1, int(rr_y_centroid_c)-1), 4, color='red', linewidth=3, fill=False) #test functining of PVN intersection\n",
    "            #     ax3.add_patch(circ) #test functining of PVN intersection\n",
    "    \n",
    "    \n",
    "    blobs_in_PVNcells_yx_rrcc_final_dict_Ch1 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list of tuples, each tuple containg in order the y_coordinate (row position), x_coordinate (column position) and radius of each blob in the cell, detected in Channel 1\n",
    "    blobs_in_PVNcells_yx_rrcc_final_dict_Ch2 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list of tuples, each tuple containg in order the y_coordinate (row position), x_coordinate (column position) and radius of each blob in the cell, detected in Channel 2\n",
    "    blobs_in_PVNcells_yx_rrcc_final_dict_Ch3 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list of tuples, each tuple containg in order the y_coordinate (row position), x_coordinate (column position) and radius of each blob in the cell, detected in Channel 3\n",
    "    \n",
    "    blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch1 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a tuple containg in order the mean and standard deviation of the radii of the blobs in the cell, detected in Channel 1\n",
    "    blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch2 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a tuple containg in order the mean and standard deviation of the radii of the blobs in the cell, detected in Channel 2\n",
    "    blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch3 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a tuple containg in order the mean and standard deviation of the radii of the blobs in the cell, detected in Channel 3\n",
    "    \n",
    "    maxima_in_PVNcells_yx_rrcc_final_dict_Ch1 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list of tuples, each tuple containg in order the y_coordinate (row position), x_coordinate (column position) of the maxima in the cell, detected in Channel 1\n",
    "    maxima_in_PVNcells_yx_rrcc_final_dict_Ch2 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list of tuples, each tuple containg in order the y_coordinate (row position), x_coordinate (column position) of the maxima in the cell, detected in Channel 2\n",
    "    maxima_in_PVNcells_yx_rrcc_final_dict_Ch3 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list of tuples, each tuple containg in order the y_coordinate (row position), x_coordinate (column position) of the maxima in the cell, detected in Channel 3\n",
    "    \n",
    "    meanintensity_PVNcells_final_dict_Ch1 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list containing a single value: the mean intensity of Channel 1 for that cell\n",
    "    meanintensity_PVNcells_final_dict_Ch2 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list containing a single value: the mean intensity of Channel 2 for that cell\n",
    "    meanintensity_PVNcells_final_dict_Ch3 = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list containing a single value: the mean intensity of Channel 3 for that cell\n",
    "    \n",
    "    area_PVNcells_yx_final_dict = {} #OUTPUT DICTIONARY mapping PVN-cell names to a list containing a single value: the area of the cell calculated as number of pixels (see skimage.measure.regionprops)\n",
    "        \n",
    "    #loop through PVN cells to get their properties (number of maxima, number of blobs, area ecc...)\n",
    "    for cell_n in names_of_cells_in_pvn:\n",
    "        \n",
    "        #get the roi file of cell in PVN - extract coordinates and cell mask - organize coordinates as a list of tuple\n",
    "        cell_roi = cells_dict[cell_n]\n",
    "        if cell_n != cell_roi.name:\n",
    "            print(\"the cell name has not been associated with the correct roi\")\n",
    "        cell_mask, cell_rr, cell_cc = form_polygon(rescaled_Ch1_Ch2_Ch3[0], cell_roi.coordinates())\n",
    "        zipped_cell_coordinates = list(zip(list(cell_rr),list(cell_cc)))\n",
    "        \n",
    "        #define a function to: 1) intersect cells-in-PVN coordinates with blobs coordinates (in order to get blobs which are in the cell) - 2) add the radius value to each intersected coordinate -\n",
    "        # 3) modify the blobs_in_PVNcells_yx_rrcc_final_dict_Ch output dictionary (see above) by adding cell names mapped to a list of tuples, each containing in order the y_coordinate (row position), x_coordinate (column position) and radius of one of the intersected blobs -\n",
    "        #4) modify the blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch output dictionary (see above) by adding cell names mapped to a tuple containg in order the mean and standard deviation of the radii of the intesected blobs\n",
    "        def intersect_blobs_into_cell(blobs_coordinates_list_Channel,blobs_coordinates_dict_Channel, blobs_in_PVNcells_yx_rrcc_final_dict_Channel, blobs_mean_radius_stddev_in_PVNcells_final_dict_Channel):\n",
    "            intersection_blob_mask_coordinates = list(set(blobs_coordinates_list_Channel).intersection(set(zipped_cell_coordinates)))\n",
    "            blobs_plus_radius_list = []\n",
    "            cell_radii_list = []\n",
    "            for interestected_blob in intersection_blob_mask_coordinates:\n",
    "                rr_y_i_blob, cc_x_i_blob = interestected_blob[0], interestected_blob[1]\n",
    "                interestected_blob_radius = blobs_coordinates_dict_Channel[(rr_y_i_blob, cc_x_i_blob)]\n",
    "                yxr = (interestected_blob[0], interestected_blob[1], interestected_blob_radius) #coord_y_row, coord_x_column, radius\n",
    "                blobs_plus_radius_list.append(yxr)\n",
    "                cell_radii_list.append(interestected_blob_radius)\n",
    "            if len(cell_radii_list)>0:\n",
    "                cell_blobs_mean_radius_stddev = np.mean(cell_radii_list), np.std(cell_radii_list)\n",
    "            else:\n",
    "                cell_blobs_mean_radius_stddev=0.0,0.0\n",
    "            blobs_in_PVNcells_yx_rrcc_final_dict_Channel[cell_n]= blobs_plus_radius_list\n",
    "            blobs_mean_radius_stddev_in_PVNcells_final_dict_Channel[cell_n]= cell_blobs_mean_radius_stddev\n",
    "        \n",
    "        #call the function to intersect blobs of different channels with the cell in the for-loop\n",
    "        intersect_blobs_into_cell(blobs_coordinates_list_Ch1,blobs_coordinates_dict_Ch1, blobs_in_PVNcells_yx_rrcc_final_dict_Ch1, blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch1)\n",
    "        intersect_blobs_into_cell(blobs_coordinates_list_Ch2,blobs_coordinates_dict_Ch2, blobs_in_PVNcells_yx_rrcc_final_dict_Ch2, blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch2)\n",
    "        intersect_blobs_into_cell(blobs_coordinates_list_Ch3,blobs_coordinates_dict_Ch3, blobs_in_PVNcells_yx_rrcc_final_dict_Ch3, blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch3)\n",
    "        \n",
    "        #define a function to: 1) intersect cells-in-PVN coordinates with maxima coordinates (in order to get maxima which are in the cell) - \n",
    "        #2) modify the maxima_in_PVNcells_yx_rrcc_final_dict_Ch output dictionary (see above) by adding cell names mapped to a list of tuples, each containing in order the y_coordinate (row position), x_coordinate (column position) of one of the intesected maxima\n",
    "        def intersect_maxima_into_cell(maxima_results_Channel, maxima_in_PVNcells_yx_rrcc_final_dict_Channel):\n",
    "            yx_maxima_coordinates_list = list(zip(list(maxima_results_Channel[0]),list(maxima_results_Channel[1])))\n",
    "            yx_intersection_maxima_mask_coordinates = list(set(yx_maxima_coordinates_list).intersection(set(zipped_cell_coordinates)))\n",
    "            maxima_in_PVNcells_yx_rrcc_final_dict_Channel[cell_n] = yx_intersection_maxima_mask_coordinates #coord_y_row, coord_x_column\n",
    "        \n",
    "        #call the function to intersect maxima of different channels with the cell in the for-loop\n",
    "        intersect_maxima_into_cell(maxima_results[0], maxima_in_PVNcells_yx_rrcc_final_dict_Ch1)\n",
    "        intersect_maxima_into_cell(maxima_results[1], maxima_in_PVNcells_yx_rrcc_final_dict_Ch2)\n",
    "        intersect_maxima_into_cell(maxima_results[2], maxima_in_PVNcells_yx_rrcc_final_dict_Ch3)\n",
    "        \n",
    "        \n",
    "        #define a function to: 1) get intensity and area measurements of PVN-cell -\n",
    "        #2) modify the meanintensity_PVNcells_final_dict_Ch output dictionary (see above) by adding cell names mapped to a list containing a single value: the mean intensity signal for the cell in the img_2_quantify input of the function -\n",
    "        #3) modify the area_PVNcells_yx_final_dict output dictionary (see above) by adding cell names mapped to a list containing a single value: the area of the cell\n",
    "        def get_cell_properties(img_2_quantify, meanintensity_PVNcells_final_dict_Channel, area_PVNcells_yx_final_dict_Channel):\n",
    "            labeled_img = label(cell_mask)\n",
    "            prop_cell = regionprops(labeled_img, intensity_image=img_2_quantify)\n",
    "            mean_intensity_cell = prop_cell[0]['mean_intensity']\n",
    "            area_cell = prop_cell[0]['area']\n",
    "            meanintensity_PVNcells_final_dict_Channel[cell_n] = [mean_intensity_cell]\n",
    "            area_PVNcells_yx_final_dict_Channel[cell_n] = [area_cell]\n",
    "        \n",
    "        #call the function to get area and mean intensity, for different channels, of the cell in the for-loop\n",
    "        get_cell_properties(rescaled_Ch1_Ch2_Ch3[0], meanintensity_PVNcells_final_dict_Ch1, area_PVNcells_yx_final_dict)\n",
    "        get_cell_properties(rescaled_Ch1_Ch2_Ch3[1], meanintensity_PVNcells_final_dict_Ch2, area_PVNcells_yx_final_dict)\n",
    "        get_cell_properties(rescaled_Ch1_Ch2_Ch3[2], meanintensity_PVNcells_final_dict_Ch3, area_PVNcells_yx_final_dict)\n",
    "    \n",
    "    \n",
    "    #test functioning of blobs and maxima intersection - NOTE: THIS FUNCTION CONTAINS A WHILE LOOP THAT CAN GO ON FORWEVER IF THERE ARE NO BLOBS OR MAXIMA DETECTED IN ANY CELL OF THE IMAGE\n",
    "    def pick_a_lucky_cell(cell_name_list, blobs_maxima_in_PVNcells_yx_rrcc_final_dict_Channel):\n",
    "        \"\"\"\n",
    "        inputs: list of cell names; dictionary associating each cell name to a list of tuples, each tuple containg in position 0 the y_coordinate (row position) and in position 1 the x_coordinate (column position) of an element (blob, maxima)\n",
    "        NOTE: the function doesn't have output, it generates a picture showing a cell and as many circles as the elements (blobs, maxima) associated to the cell, the circles are centered on the coordinates of the elements\n",
    "        NOTE: even though it is not required in the input, the function requires an axis to plot the cell and the elements, this is done by modifyin the \"ax3\" with the name of the axis to use\n",
    "        IMPORTANT NOTE: the cell is picked randomly among those which have at least 1 element (blob or maxima) associatated, this means that if there is not even 1 cell which has at least 1 element, the function will loop forever\n",
    "        NOTE: the function works for blobs and maxima, in principle it can be easily adapted to also plot centroids\n",
    "        \"\"\"\n",
    "        lucky_cell = random.sample(cell_name_list, k = 1)[0]\n",
    "        n_cell_blobs_maxima = len(blobs_maxima_in_PVNcells_yx_rrcc_final_dict_Channel[lucky_cell])\n",
    "        while n_cell_blobs_maxima<1: #NOTE: THIS WHILE LOOP CAN GO ON FORWEVER IF THERE ARE NO BLOBS OR MAXIMA DETECTED IN ANY CELL OF THE IMAGE\n",
    "            lucky_cell = random.sample(cell_name_list, k = 1)[0]\n",
    "            n_cell_blobs_maxima = len(blobs_maxima_in_PVNcells_yx_rrcc_final_dict_Channel[lucky_cell])\n",
    "        \n",
    "        lucky_cell_roi = cells_dict[lucky_cell]\n",
    "        lucky_cell_mask, lucky_cell_rr, lucky_cell_cc = form_polygon(rescaled_Ch1_Ch2_Ch3[0], lucky_cell_roi.coordinates())\n",
    "        lucky_cell_blobs_maxima = blobs_maxima_in_PVNcells_yx_rrcc_final_dict_Channel[lucky_cell]\n",
    "        # print(lucky_cell_blobs_maxima)\n",
    "        # ax3.imshow(lucky_cell_mask) #test functining of blobs intersection, uncomment the cell and provide an axis to check blobs and maxima intersection functioning\n",
    "        for lbm in lucky_cell_blobs_maxima:\n",
    "            lbm_rr_y, lbm_cc_x = lbm[0], lbm[1]\n",
    "            lbm_circ = plt.Circle((lbm_cc_x, lbm_rr_y), 4, color='red', linewidth=3, fill=False) #test functining of blobs intersection\n",
    "            # ax3.add_patch(lbm_circ) #test functining of blobs intersection, uncomment the cell and provide an axis to check blobs and maxima intersection functioning\n",
    "    \n",
    "    #test functining of blobs intersection - uncomment the cell below to test blob intersection - NOTE: AN AXIS MUST BE PROVIDED BY MODIFYING THE pick_a_lucky_cell FUNCTION ABOVE; THIS FUNCTION MIGHT LOOP FOREVER (SEE DESCRIPTION ABOVE)\n",
    "    # pick_a_lucky_cell(names_of_cells_in_pvn, blobs_in_PVNcells_yx_rrcc_final_dict_Ch1)\n",
    "    \n",
    "    #test functining of maxima intersection - uncomment the cell below to test maxima intersection - NOTE: AN AXIS MUST BE PROVIDED BY MODIFYING THE pick_a_lucky_cell FUNCTION ABOVE; THIS FUNCTION MIGHT LOOP FOREVER (SEE DESCRIPTION ABOVE)\n",
    "    # pick_a_lucky_cell(names_of_cells_in_pvn, maxima_in_PVNcells_yx_rrcc_final_dict_Ch1)\n",
    "    \n",
    "    tuple_output = (blobs_in_PVNcells_yx_rrcc_final_dict_Ch1, blobs_in_PVNcells_yx_rrcc_final_dict_Ch2, blobs_in_PVNcells_yx_rrcc_final_dict_Ch3, blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch1, blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch2, blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch3, maxima_in_PVNcells_yx_rrcc_final_dict_Ch1, maxima_in_PVNcells_yx_rrcc_final_dict_Ch2, maxima_in_PVNcells_yx_rrcc_final_dict_Ch3, meanintensity_PVNcells_final_dict_Ch1, meanintensity_PVNcells_final_dict_Ch2, meanintensity_PVNcells_final_dict_Ch3, area_PVNcells_yx_final_dict, nuclei_centroids_yx_rrcc_dict, area_nucleus_PVNcells_final_dict)\n",
    "    \n",
    "    return tuple_output\n",
    "\n",
    "\n",
    "\n",
    "def form_principal_dataframe(experiment_n, sex_n, mouse_n, slice_pos_n, results_tuple):\n",
    "    \"\"\"\n",
    "    spreads cell measurements from GetCiPVNwIntMaxBlobs function on a dictionary which can be used to generate a dataframe where rows are individual cells and columns are cells following properties:\n",
    "    experiment, sex, mouse, slice_position, cell name, number of blobs in Ch1, number of blobs in Ch2, number of blobs in Ch3, mean radius of blobs in Ch1, standard deviation of blobs in Ch1, mean radius of blobs in Ch2, standard deviation of blobs in Ch2,\n",
    "    mean radius of blobs in Ch3, standard deviation of blobs in Ch3, number of maxima in Ch1, number of maxima in Ch2, number of maxima in Ch3, mean signal intensity in Ch1, mean signal intensity in Ch2, mean signal intensity in Ch3,\n",
    "    area of cell (pixel number), y coordinate of cell nucleus centroid (used to assign the cell to PVN), x coordinate of cell nucleus centroid (used to assign the cell to PVN), area of cell nucleus\n",
    "    \n",
    "    inputs: name of the experiment (string), sex (string), mouse name (string), slice position (string), tuple of results from GetCiPVNwIntMaxBlobs\n",
    "    results of GetCiPVNwIntMaxBlobs function are the following, I also indicate, per each measurement how it is organized\n",
    "    # 0 blobs_in_PVNcells_yx_rrcc_final_dict_Ch1; {\"c1\":[(y_rr,x_cc,radius),(y_rr,x_cc,radius)], \"c2\":[(y_rr,x_cc,radius), (y_rr,x_cc,radius)]}\n",
    "    # 1 blobs_in_PVNcells_yx_rrcc_final_dict_Ch2; {\"c1\":[(y_rr,x_cc,radius),(y_rr,x_cc,radius)], \"c2\":[(y_rr,x_cc,radius), (y_rr,x_cc,radius)]}\n",
    "    # 2 blobs_in_PVNcells_yx_rrcc_final_dict_Ch3; {\"c1\":[(y_rr,x_cc,radius),(y_rr,x_cc,radius)], \"c2\":[(y_rr,x_cc,radius), (y_rr,x_cc,radius)]}\n",
    "    # 3 blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch1; {\"c1\":(mean_radius,std_dev), \"c2\":(mean_radius,std_dev)}\n",
    "    # 4 blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch2; {\"c1\":(mean_radius,std_dev), \"c2\":(mean_radius,std_dev)}\n",
    "    # 5 blobs_mean_radius_stddev_in_PVNcells_final_dict_Ch3; {\"c1\":(mean_radius,std_dev), \"c2\":(mean_radius,std_dev)}\n",
    "    # 6 maxima_in_PVNcells_yx_rrcc_final_dict_Ch1; {\"c1\":[(y_rr,x_cc),(y_rr,x_cc)], \"c2\":[(y_rr,x_cc), (y_rr,x_cc)]}\n",
    "    # 7 maxima_in_PVNcells_yx_rrcc_final_dict_Ch2; {\"c1\":[(y_rr,x_cc),(y_rr,x_cc)], \"c2\":[(y_rr,x_cc), (y_rr,x_cc)]}\n",
    "    # 8 maxima_in_PVNcells_yx_rrcc_final_dict_Ch3; {\"c1\":[(y_rr,x_cc),(y_rr,x_cc)], \"c2\":[(y_rr,x_cc), (y_rr,x_cc)]}\n",
    "    # 9 meanintensity_PVNcells_final_dict_Ch1; {\"c1\":[mean], \"c2\":[mean]}\n",
    "    # 10 meanintensity_PVNcells_final_dict_Ch2; {\"c1\":[mean], \"c2\":[mean]}\n",
    "    # 11 meanintensity_PVNcells_final_dict_Ch3; {\"c1\":[mean], \"c2\":[mean]}\n",
    "    # 12 area_PVNcells_yx_final_dict; {\"c1\":[area], \"c2\":[area]}\n",
    "    # 13 nuclei_centroids_yx_rrcc_dict; {\"c1\":(y_rr,x_cc), \"c2\":(y_rr,x_cc)}\n",
    "    # 14 area_nucleus_PVNcells_final_dict; {\"c1\":[area], \"c2\":[area]}\n",
    "    \n",
    "    outputs: dictionary: per each feature/measured_property, the feature/measured_property, as a string, is associated to a list of length equal to number_of_analyzed_cells and values equal to the corresponding feature/measured_property. Cell identity is maintained as the position in each list.\n",
    "    \"\"\"\n",
    "    \n",
    "    final_dict = {}\n",
    "    \n",
    "    for c in results_tuple[0]:\n",
    "        if 'experiment' not in final_dict:\n",
    "            final_dict['experiment']=[experiment_n]\n",
    "        else:\n",
    "            final_dict['experiment'].append(experiment_n)\n",
    "            \n",
    "        if 'sex' not in final_dict:\n",
    "            final_dict['sex']=[sex_n]\n",
    "        else:\n",
    "            final_dict['sex'].append(sex_n)\n",
    "            \n",
    "        if 'mouse' not in final_dict:\n",
    "            final_dict['mouse']=[mouse_n]\n",
    "        else:\n",
    "            final_dict['mouse'].append(mouse_n)\n",
    "            \n",
    "        if 'slice_position' not in final_dict:\n",
    "            final_dict['slice_position']=[slice_pos_n]\n",
    "        else:\n",
    "            final_dict['slice_position'].append(slice_pos_n)\n",
    "            \n",
    "        if 'cell' not in final_dict:\n",
    "            final_dict['cell']=[c]\n",
    "        else:\n",
    "            final_dict['cell'].append(c)\n",
    "            \n",
    "        if 'blobs_number_Ch1' not in final_dict:\n",
    "            final_dict['blobs_number_Ch1']=[len(results_tuple[0][c])]\n",
    "        else:\n",
    "            final_dict['blobs_number_Ch1'].append(len(results_tuple[0][c]))\n",
    "            \n",
    "        if 'blobs_number_Ch2' not in final_dict:\n",
    "            final_dict['blobs_number_Ch2']=[len(results_tuple[1][c])]\n",
    "        else:\n",
    "            final_dict['blobs_number_Ch2'].append(len(results_tuple[1][c]))\n",
    "            \n",
    "        if 'blobs_number_Ch3' not in final_dict:\n",
    "            final_dict['blobs_number_Ch3']=[len(results_tuple[2][c])]\n",
    "        else:\n",
    "            final_dict['blobs_number_Ch3'].append(len(results_tuple[2][c]))\n",
    "                \n",
    "        if 'mean_blob_radius_Ch1' not in final_dict:\n",
    "            final_dict['mean_blob_radius_Ch1']=[results_tuple[3][c][0]]\n",
    "        else:\n",
    "            final_dict['mean_blob_radius_Ch1'].append(results_tuple[3][c][0])\n",
    "            \n",
    "        if 'std_dev_blob_radius_Ch1' not in final_dict:\n",
    "            final_dict['std_dev_blob_radius_Ch1']=[results_tuple[3][c][1]]\n",
    "        else:\n",
    "            final_dict['std_dev_blob_radius_Ch1'].append(results_tuple[3][c][1])\n",
    "            \n",
    "        if 'mean_blob_radius_Ch2' not in final_dict:\n",
    "            final_dict['mean_blob_radius_Ch2']=[results_tuple[4][c][0]]\n",
    "        else:\n",
    "            final_dict['mean_blob_radius_Ch2'].append(results_tuple[4][c][0])\n",
    "            \n",
    "        if 'std_dev_blob_radius_Ch2' not in final_dict:\n",
    "            final_dict['std_dev_blob_radius_Ch2']=[results_tuple[4][c][1]]\n",
    "        else:\n",
    "            final_dict['std_dev_blob_radius_Ch2'].append(results_tuple[4][c][1])\n",
    "            \n",
    "        if 'mean_blob_radius_Ch3' not in final_dict:\n",
    "            final_dict['mean_blob_radius_Ch3']=[results_tuple[5][c][0]]\n",
    "        else:\n",
    "            final_dict['mean_blob_radius_Ch3'].append(results_tuple[5][c][0])\n",
    "            \n",
    "        if 'std_dev_blob_radius_Ch3' not in final_dict:\n",
    "            final_dict['std_dev_blob_radius_Ch3']=[results_tuple[5][c][1]]\n",
    "        else:\n",
    "            final_dict['std_dev_blob_radius_Ch3'].append(results_tuple[5][c][1])\n",
    "            \n",
    "        if 'maxima_number_Ch1' not in final_dict:\n",
    "            final_dict['maxima_number_Ch1']=[len(results_tuple[6][c])]\n",
    "        else:\n",
    "            final_dict['maxima_number_Ch1'].append(len(results_tuple[6][c]))\n",
    "            \n",
    "        if 'maxima_number_Ch2' not in final_dict:\n",
    "            final_dict['maxima_number_Ch2']=[len(results_tuple[7][c])]\n",
    "        else:\n",
    "            final_dict['maxima_number_Ch2'].append(len(results_tuple[7][c]))\n",
    "            \n",
    "        if 'maxima_number_Ch3' not in final_dict:\n",
    "            final_dict['maxima_number_Ch3']=[len(results_tuple[8][c])]\n",
    "        else:\n",
    "            final_dict['maxima_number_Ch3'].append(len(results_tuple[8][c]))\n",
    "            \n",
    "        if 'mean_intensity_Ch1' not in final_dict:\n",
    "            final_dict['mean_intensity_Ch1']=[results_tuple[9][c][0]]\n",
    "        else:\n",
    "            final_dict['mean_intensity_Ch1'].append(results_tuple[9][c][0])\n",
    "            \n",
    "        if 'mean_intensity_Ch2' not in final_dict:\n",
    "            final_dict['mean_intensity_Ch2']=[results_tuple[10][c][0]]\n",
    "        else:\n",
    "            final_dict['mean_intensity_Ch2'].append(results_tuple[10][c][0])\n",
    "            \n",
    "        if 'mean_intensity_Ch3' not in final_dict:\n",
    "            final_dict['mean_intensity_Ch3']=[results_tuple[11][c][0]]\n",
    "        else:\n",
    "            final_dict['mean_intensity_Ch3'].append(results_tuple[11][c][0])\n",
    "            \n",
    "        if 'area_cell' not in final_dict:\n",
    "            final_dict['area_cell']=[results_tuple[12][c][0]]\n",
    "        else:\n",
    "            final_dict['area_cell'].append(results_tuple[12][c][0])\n",
    "            \n",
    "        if 'nucleus_centroid_row_y' not in final_dict:\n",
    "            final_dict['nucleus_centroid_row_y']=[results_tuple[13][c][0]]\n",
    "        else:\n",
    "            final_dict['nucleus_centroid_row_y'].append(results_tuple[13][c][0])\n",
    "            \n",
    "        if 'nucleus_centroid_col_x' not in final_dict:\n",
    "            final_dict['nucleus_centroid_col_x']=[results_tuple[13][c][1]]\n",
    "        else:\n",
    "            final_dict['nucleus_centroid_col_x'].append(results_tuple[13][c][1])\n",
    "        \n",
    "        if 'area_nucleus' not in final_dict:\n",
    "            final_dict['area_nucleus']=[results_tuple[14][c][0]]\n",
    "        else:\n",
    "            final_dict['area_nucleus'].append(results_tuple[14][c][0])\n",
    "    \n",
    "    return final_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c72e863-1290-4588-9af3-b1b4e4da08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "working on:  M_07_fron_MAX_cut\n",
      "finished:  M_07_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_06_fron_MAX_cut\n",
      "finished:  F_06_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_12_fron_MAX_cut\n",
      "finished:  F_12_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_20_back_MAX_cut\n",
      "finished:  F_20_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_04_back_MAX_cut\n",
      "finished:  M_04_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_02_fron_MAX_cut\n",
      "finished:  F_02_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_03_fron_MAX_cut\n",
      "finished:  M_03_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_13_fron_MAX_cut\n",
      "finished:  F_13_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_17_fron_MAX_cut\n",
      "finished:  F_17_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_09_fron_MAX_cut\n",
      "finished:  M_09_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_05_back_MAX_cut\n",
      "finished:  M_05_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_02_fron_MAX_cut\n",
      "finished:  M_02_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_11_back_MAX_cut\n",
      "finished:  M_11_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_03_fron_MAX_cut\n",
      "finished:  F_03_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_10_back_MAX_cut\n",
      "finished:  F_10_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_11_fron_MAX_cut\n",
      "finished:  M_11_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_02_back_MAX_cut\n",
      "finished:  M_02_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_10_fron_MAX_cut\n",
      "finished:  F_10_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_03_back_MAX_cut\n",
      "finished:  F_03_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_09_back_MAX_cut\n",
      "finished:  M_09_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_17_back_MAX_cut\n",
      "finished:  F_17_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_05_fron_MAX_cut\n",
      "finished:  M_05_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_01_fron_MAX_cut\n",
      "finished:  M_01_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_13_back_MAX_cut\n",
      "finished:  F_13_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_02_back_MAX_cut\n",
      "finished:  F_02_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_03_back_MAX_cut\n",
      "finished:  M_03_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_04_fron_MAX_cut\n",
      "finished:  M_04_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_12_back_MAX_cut\n",
      "finished:  F_12_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_20_fron_MAX_cut\n",
      "finished:  F_20_fron_MAX_cut\n",
      "-------------------------\n",
      "working on:  M_07_back_MAX_cut\n",
      "finished:  M_07_back_MAX_cut\n",
      "-------------------------\n",
      "working on:  F_06_back_MAX_cut\n",
      "finished:  F_06_back_MAX_cut\n",
      "Experiment2_results.csv\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#iterate processing on images\n",
    "\n",
    "def pipeline_processing(img):\n",
    "    #form paths for files to be used (images and rois)\n",
    "    orig_img_path = os.path.join(home_directory, os.path.join(step1_path_output, organized_dictionary[img]['original_image']))\n",
    "    pvn_roi_path = os.path.join(home_directory, os.path.join(step1_path_output, organized_dictionary[img]['rois_pvn']))\n",
    "    cells_roi_path = os.path.join(home_directory, os.path.join(step3_path_output, organized_dictionary[img]['cell_rois']))\n",
    "    \n",
    "    #open image and split channels\n",
    "    orig_img = tifffile.imread(orig_img_path)\n",
    "    ch1_img = orig_img[0,:,:]\n",
    "    ch2_img = orig_img[1,:,:]\n",
    "    ch3_img = orig_img[2,:,:]\n",
    "    ch4_img = orig_img[3,:,:] #DAPI\n",
    "    \n",
    "    #intensity histogram rescaling\n",
    "    equalized_np_ch1 = my_intensity_rescaling(ch1_img, min_percentil, max_percentil) #NOTE: the rescaling is done using the mode value as minimum, it is assumed the mode will reflect the tissue background\n",
    "    equalized_np_ch2 = my_intensity_rescaling(ch2_img, min_percentil, max_percentil) #NOTE: the rescaling is done using the mode value as minimum, it is assumed the mode will reflect the tissue background\n",
    "    equalized_np_ch3 = my_intensity_rescaling(ch3_img, min_percentil, max_percentil) #NOTE: the rescaling is done using the mode value as minimum, it is assumed the mode will reflect the tissue background\n",
    "    \n",
    "    #detect blobs in each channel\n",
    "    blobs_log_Ch1 = blob_log(equalized_np_ch1, min_sigma=min_sigma_Ch1, max_sigma=max_sigma_Ch1, num_sigma=num_sigma_Ch1, threshold=threshold_Ch1, overlap=overlap_Ch1)\n",
    "    blobs_log_Ch2 = blob_log(equalized_np_ch2, min_sigma=min_sigma_Ch2, max_sigma=max_sigma_Ch2, num_sigma=num_sigma_Ch2, threshold=threshold_Ch2, overlap=overlap_Ch2)\n",
    "    blobs_log_Ch3 = blob_log(equalized_np_ch3, min_sigma=min_sigma_Ch3, max_sigma=max_sigma_Ch3, num_sigma=num_sigma_Ch3, threshold=threshold_Ch3, overlap=overlap_Ch3)\n",
    "    \n",
    "    #maxima detection\n",
    "    #maxima detection - rescaling of images as int16 with range 0,255\n",
    "    rescaled_Ch1 = img_as_ubyte(equalized_np_ch1)\n",
    "    rescaled_Ch2 = img_as_ubyte(equalized_np_ch2)\n",
    "    rescaled_Ch3 = img_as_ubyte(equalized_np_ch3)\n",
    "    #detect maxima in each channel\n",
    "    maxima_Ch1 = my_find_maxima(rescaled_Ch1, maxima_threshold_Ch1)\n",
    "    maxima_Ch2 = my_find_maxima(rescaled_Ch2, maxima_threshold_Ch2)\n",
    "    maxima_Ch3 = my_find_maxima(rescaled_Ch3, maxima_threshold_Ch3)\n",
    "    \n",
    "    #open PVN and Cells rois\n",
    "    pvn_rois = ImagejRoi.fromfile(pvn_roi_path)\n",
    "    cells_rois = ImagejRoi.fromfile(cells_roi_path)\n",
    "    \n",
    "    #Select/measure properties of cells in the PVNs\n",
    "    if organized_dictionary[img]['rois_pvn'][-4:]=='.roi':\n",
    "        measure_results = GetCiPVNwIntMaxBlobs((equalized_np_ch1, equalized_np_ch2, equalized_np_ch3), pvn_rois, cells_rois, (blobs_log_Ch1,blobs_log_Ch2,blobs_log_Ch3), (maxima_Ch1,maxima_Ch2,maxima_Ch3), False)\n",
    "        print(img, \"individual pvn file\")\n",
    "    else:\n",
    "        measure_results = GetCiPVNwIntMaxBlobs((equalized_np_ch1, equalized_np_ch2, equalized_np_ch3), pvn_rois, cells_rois, (blobs_log_Ch1,blobs_log_Ch2,blobs_log_Ch3), (maxima_Ch1,maxima_Ch2,maxima_Ch3), True)\n",
    "    \n",
    "    \n",
    "    #get experiment, sex, mouse and slice_position information\n",
    "    \n",
    "    #Define a function to slice strings according to indicated delimeters. A delimiter indicated as None is interpreted as no delimiter should be used. This allows to include the beginning and the end of the string in the slicing process\n",
    "    #The function is used to get the experiment sex, mouse and slice_position names, according to the slice delimiters defined in the hyperparameter settings\n",
    "    def get_name_of_interest(string_2_slice, slice_delimiter_1, slice_delimiter_2):\n",
    "        if (slice_delimiter_1==None and slice_delimiter_2==None):\n",
    "            name_of_interest = string_2_slice[:]\n",
    "        elif (slice_delimiter_1==None and slice_delimiter_2!=None):\n",
    "            name_of_interest = string_2_slice[:slice_delimiter_2]\n",
    "        elif slice_delimiter_1!=None and slice_delimiter_2==None:\n",
    "            name_of_interest = string_2_slice[slice_delimiter_1:]\n",
    "        else:\n",
    "            name_of_interest = string_2_slice[slice_delimiter_1:slice_delimiter_2]\n",
    "        return name_of_interest\n",
    "    \n",
    "    #Get experiment name\n",
    "    if isinstance(experiment_position, str):\n",
    "        experiment = experiment_position\n",
    "    else:\n",
    "        experiment = get_name_of_interest(home_directory, experiment_position[0],experiment_position[1]) #Get experiment name\n",
    "    \n",
    "    #Get sex name\n",
    "    if isinstance(sex_position, str):\n",
    "        sex = sex_position\n",
    "    else:\n",
    "        sex = get_name_of_interest(img, sex_position[0],sex_position[1]) #Get Sex name\n",
    "    \n",
    "    #Get mouse name\n",
    "    if isinstance(mouse_position, str):\n",
    "        mouse = mouse_position\n",
    "    else:\n",
    "        mouse = get_name_of_interest(img, mouse_position[0],mouse_position[1]) #Get mouse name\n",
    "    \n",
    "    #Get slice position\n",
    "    if isinstance(slice_position, str):\n",
    "        slice_pos = slice_position\n",
    "    else:\n",
    "        slice_pos = get_name_of_interest(img, slice_position[0],slice_position[1]) #Get slice_position name\n",
    "    \n",
    "    #Generate final dictionary\n",
    "    my_final_dict = form_principal_dataframe(experiment, sex, mouse, slice_pos, measure_results)\n",
    "    \n",
    "    #Create final dataframe\n",
    "    experiment_results_dataframe = pd.DataFrame.from_dict(my_final_dict)\n",
    "    \n",
    "    return experiment_results_dataframe\n",
    "\n",
    "\n",
    "#Iterate through all images and collect results in a list\n",
    "results_dataframe_list = []\n",
    "for img_n in organized_dictionary:\n",
    "    print(\"-------------------------\")\n",
    "    print(\"working on: \", img_n)\n",
    "    img_results_df = pipeline_processing(img_n)\n",
    "    results_dataframe_list.append(img_results_df)\n",
    "    print(\"finished: \", img_n)\n",
    "\n",
    "#Concatenate all dataframes in a single, final file\n",
    "results_dataframe = pd.concat(results_dataframe_list,axis=0)\n",
    "\n",
    "# print(results_dataframe)\n",
    "\n",
    "#Save the result\n",
    "output_name = home_directory[-11:] + \"_results.csv\"\n",
    "print(output_name)\n",
    "results_dataframe.to_csv(os.path.join(home_directory, output_name), index=False)\n",
    "\n",
    "print(\"Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b228ba-eb99-4fc2-97fc-643266aba91a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
